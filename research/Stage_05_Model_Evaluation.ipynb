{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c32cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540da4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from src.vision_Transformer.utils.common import read_yaml , create_directories\n",
    "from src.vision_Transformer.constants import *\n",
    "from src.vision_Transformer.logging import logger\n",
    "import tqdm \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4308792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen = True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir : Path\n",
    "    test_accuracy : Path\n",
    "    data_dir : Path\n",
    "\n",
    "    batch_size : int\n",
    "    epochs : int \n",
    "    learning_rate : float\n",
    "    patch_size : int\n",
    "    num_classes : int\n",
    "    image_size : int \n",
    "    channels : int\n",
    "    embed_dim : int\n",
    "    num_heads: int\n",
    "    depth : int\n",
    "    mlp_dim : int\n",
    "    dropout_rate : float\n",
    "    weight_decay : float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca3f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self , config_file_path = CONFIG_FILE_PATH , params_file_path = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_evalutaion_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        params = self.params.TrainingArguments\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir = config.root_dir , \n",
    "            test_accuracy= config.test_accuracy,\n",
    "            data_dir= config.data_dir,\n",
    "\n",
    "            batch_size= params.BATCH_SIZE,\n",
    "            epochs = params.EPOCHS,\n",
    "            learning_rate = params.LEARNING_RATE,\n",
    "            patch_size = params.PATCH_SIZE,\n",
    "            num_classes = params.NUM_CLASSES,\n",
    "            image_size = params.IMAGE_SIZE,\n",
    "            channels = params.CHANNELS,\n",
    "            embed_dim  = params.EMBED_DIM,\n",
    "            num_heads = params.NUM_HEADS,\n",
    "            depth = params.DEPTH,\n",
    "            mlp_dim = params.MLP_DIM,\n",
    "            dropout_rate = params.DROPOUT_RATE,\n",
    "            weight_decay  = params.WEIGHT_DECAY\n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8731bd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.vision_Transformer.Components.ViT_Component.Vision_Transformer_Class import Vision_Transformer_Class\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d84ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vision_Transformer.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49966a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self , config : ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def data_augmentation(self):\n",
    "        self.after_transforms = transforms.Compose([\n",
    "            transforms.RandomCrop(32 , padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.2 ,contrast= 0.2, saturation=0.2 , hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5]*3 , std = [0.5]*3)\n",
    "        ])\n",
    "    \n",
    "    def transformed_dataset(self):\n",
    "        transformed_test_dataset = datasets.CIFAR10(\n",
    "            root = self.config.data_dir,\n",
    "            train = False,\n",
    "            download= False,\n",
    "            transform= self.after_transforms,\n",
    "        )\n",
    "        logger.info(f\"Test Dataset Transformed Successfully\")\n",
    "        print(f\"Test Dataset Transformed Successfully\")\n",
    "\n",
    "        return transformed_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b54c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-09 14:24:20,219 : INFO : common  : yaml file config\\config.yaml was read succesfully]\n",
      "[2025-08-09 14:24:20,226 : INFO : common  : yaml file params.yaml was read succesfully]\n",
      "[2025-08-09 14:24:20,227 : INFO : common  : Created directory at : artifacts]\n",
      "[2025-08-09 14:24:20,227 : INFO : common  : Created directory at : artifacts/model_evaluation]\n",
      "[2025-08-09 14:24:20,681 : INFO : 1566778438  : Test Dataset Transformed Successfully]\n",
      "Test Dataset Transformed Successfully\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "model_eval_config = config.get_model_evalutaion_config()\n",
    "\n",
    "data_transfromation = DataTransformation(model_eval_config)\n",
    "data_transfromation.data_augmentation()\n",
    "\n",
    "test_dataset = data_transfromation.transformed_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ff0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10372ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, config : ConfigurationManager , test_dataset):\n",
    "        self.config = config\n",
    "        \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "        self.test_loader =  DataLoader(test_dataset , batch_size = self.config.batch_size ,shuffle = False ,pin_memory= True)\n",
    "\n",
    "        self.model = torch.load(\"\").to(self.device)\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing= 0.1)\n",
    "        self.optimizer = optim.AdamW(self.model.parameters() , lr = float(self.config.learning_rate) , weight_decay= self.config.weight_decay)\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer= self.optimizer , T_max= self.config.epochs)\n",
    "    \n",
    "    # ---------------------------------------------------------------------------\n",
    "    def show_model(self):\n",
    "        print(\"\\n\\n------------------------------->Model Configuration<------------------------------------\")\n",
    "        print(\"\\n\", self.model)\n",
    "\n",
    "        print(\"\\n\\n\\n\", self.device)\n",
    "        \n",
    "    def evaluate(self):\n",
    "        #set the model to the testing mode \n",
    "        self.model.eval()\n",
    "        \n",
    "\n",
    "        total_loss , correct_prediction = 0 , 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x , y in self.test_loader:\n",
    "                x , y = x.to(self.device) , y.to(self.device)\n",
    "\n",
    "                output = self.model(x)\n",
    "\n",
    "                loss = self.criterion(output , y)\n",
    "\n",
    "                correct_prediction += (output.argmax(1) == y).sum().item()\n",
    "\n",
    "        return correct_prediction / len(self.test_loader.dataset)\n",
    "    \n",
    "\n",
    "    def model_test_pipeline(self):\n",
    "        test_accuracy_log= []\n",
    "        test_accuracy_file = self.config.test_accuray\n",
    "\n",
    "        os.makedirs(os.path.dirname(test_accuracy_file) , exist_ok= True)\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(self.config.epochs)):\n",
    "\n",
    "            test_acc = self.evaluate()\n",
    "\n",
    "            log = {\n",
    "            \"epoch\": f\" {epoch+1} /{self.config.epochs}\",\n",
    "            \"test_acc\": f\" {test_acc:.4f}%\"\n",
    "            }\n",
    "\n",
    "            test_accuracy_log.append(log)\n",
    "\n",
    "            print(f\"Epoch: {epoch+1}/{self.config.epochs} , Test acc: {test_acc:.4f}%\")\n",
    "\n",
    "        with open(test_accuracy_file, 'w') as f:\n",
    "            json.dump(test_accuracy_log , f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e88c328c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-09 14:24:40,551 : INFO : common  : yaml file config\\config.yaml was read succesfully]\n",
      "[2025-08-09 14:24:40,560 : INFO : common  : yaml file params.yaml was read succesfully]\n",
      "[2025-08-09 14:24:40,561 : INFO : common  : Created directory at : artifacts]\n",
      "[2025-08-09 14:24:40,562 : INFO : common  : Created directory at : artifacts/model_evaluation]\n",
      "[2025-08-09 14:24:40,960 : INFO : 1566778438  : Test Dataset Transformed Successfully]\n",
      "Test Dataset Transformed Successfully\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m -----------Model Evaluation Completed----------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m data_transfromation\u001b[38;5;241m.\u001b[39mdata_augmentation()\n\u001b[0;32m      9\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m data_transfromation\u001b[38;5;241m.\u001b[39mtransformed_dataset()\n\u001b[1;32m---> 11\u001b[0m model_evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mModelEvaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_evaluation_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m -----------Model Evaluation Started----------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m model_evaluation\u001b[38;5;241m.\u001b[39mmodel_test_pipeline()\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36mModelEvaluation.__init__\u001b[1;34m(self, config, test_dataset)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;241m=\u001b[39m test_dataset\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m  DataLoader(test_dataset , batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size ,shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m ,pin_memory\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(label_smoothing\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    config = ConfigurationManager()\n",
    "\n",
    "    model_evaluation_config = config.get_model_evalutaion_config()\n",
    "\n",
    "    data_transfromation = DataTransformation(model_eval_config)\n",
    "    data_transfromation.data_augmentation()\n",
    "\n",
    "    test_dataset = data_transfromation.transformed_dataset()\n",
    "\n",
    "    model_evaluation = ModelEvaluation(model_evaluation_config, test_dataset= test_dataset)\n",
    "\n",
    "    print(\"\\n\\n -----------Model Evaluation Started----------------------\")\n",
    "    \n",
    "    model_evaluation.model_test_pipeline()\n",
    "\n",
    "    print(\"\\n\\n -----------Model Evaluation Completed----------------------\")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431b2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
